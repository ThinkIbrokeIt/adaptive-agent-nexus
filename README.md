# Adaptive Agent Nexus v0.7.0-alpha

## Introduction

The Adaptive Agent Nexus is an intelligent system designed to bring context-aware, self-learning capabilities to AI agents. By implementing the innovative Monitor-Contextualize-Personalize (McP) workflow architecture, this platform enables agents to:

- **Learn from interactions** through continuous feedback loops
- **Adapt responses** based on contextual understanding
- **Improve over time** by self-optimizing knowledge representation
- **Provide personalized experiences** tailored to specific user needs

The system solves critical challenges in traditional AI implementations, including context amnesia, static knowledge representation, and one-size-fits-all responses. Through its adaptable architecture, the platform bridges the gap between raw data collection and meaningful, personalized agent interactions.

## ðŸš€ Quick Start (5 minutes)

1. **Clone & Install**:

   ```bash
   git clone https://github.com/your-username/adaptive-agent-nexus.git
   cd adaptive-agent-nexus
   npm install
   npm run dev
   ```

2. **Open**: http://localhost:5173

3. **Try**: Type `help` or click "Run MCP Workflow"

ðŸ“– **[Complete User Guide](USER_GUIDE.md)** - Instructions & Troubleshooting

## Architecture

The system is built with a modular architecture that separates concerns:

- **Agent Network**: Manages the coordination between specialized agents
- **Command Processing**: Handles different types of user commands via dedicated processors
- **Workflow Engine**: Implements the McP workflow architecture
- **Voice Interface**: Provides natural language interaction capabilities

### Agent Types

- **Primary Agent**: Handles general conversations and coordinates other agents
- **Research Agent**: Performs search and information gathering
- **Workflow Agent**: Executes the McP workflow processes
- **Data Agent**: Manages database queries and data analysis
- **Learning Agent**: Responsible for adapting the system based on feedback

## Future Roadmap

We're exploring several exciting enhancements to the platform:

- **Multi-agent collaboration** enabling specialized agents to work together
- **Advanced knowledge vector fusion** for more nuanced contextual understanding
- **Expanded self-optimization capabilities** through reinforcement learning
- **Visualization tools** for knowledge graph evolution
- **Enhanced voice interface** with emotion detection and natural conversation

## Setup and Basic Usage

### Installation

1. **Clone the repository:**

   ```
   git clone https://github.com/your-username/adaptive-agent-nexus.git
   cd adaptive-agent-nexus
   ```

2. **Install dependencies:**

   ```
   npm install
   ```

3. **Start the development server:**

   ```
   npm run dev
   ```

4. **Open in browser:**
   Open your browser and navigate to `http://localhost:5173` (or the port shown in your terminal).

### Desktop Application Packaging

The application can be packaged as native desktop applications for Windows, macOS, and Linux.

#### Quick Packaging Commands

```bash
# Build for all platforms
npm run dist

# Build for specific platforms
npm run build:electron:win     # Windows
npm run build:electron:mac     # macOS
npm run build:electron:linux   # Linux

# Development mode (web + electron)
npm run electron:dev

# Check build status
npm run package status
```

#### Generated Files

After building, you'll find the packaged applications in the `dist-electron/` directory:

- **Windows**: `.exe` installer and portable executable
- **macOS**: `.dmg` disk image
- **Linux**: `.AppImage` and `.deb` packages

#### System Requirements

- **Windows**: Windows 10 or later
- **macOS**: macOS 10.13 or later
- **Linux**: Most modern distributions

### Local Storage Mode

This version runs entirely locally using browser localStorage for data persistence. No external databases or authentication services are required.

**Data Storage:**

- Agent identities and truths are stored in your browser's localStorage
- Data persists between sessions but is browser-specific
- You can export/import data as JSON for backup or transfer

**Features Available:**

- Full agent truth file management
- Memory anchor creation
- Principle evolution tracking
- Data export/import functionality

### Data Management

**Export Data:**

- Navigate to the Agent Truth Files page
- Use the export functionality to download your data as JSON

**Import Data:**

- Use the import functionality to restore data from a JSON backup

**Clear Data:**

- Data clearing functionality is available in the truth file management interface

**Browser Storage:**

- Data is stored locally in your browser
- Clearing browser data will remove all stored information
- Use export functionality to backup important data

### LLM Configuration

The system supports multiple LLM providers for enhanced responses:

1. **Navigate to LLM Settings tab** in the main dashboard
2. **Choose your provider:**
   - **Mock**: No API required, uses simulated responses
   - **OpenAI**: GPT-4, GPT-3.5-turbo (requires API key)
   - **Anthropic**: Claude models (requires API key)
   - **Ollama**: Local models (requires Ollama installation)

3. **Configure settings:**
   - API key (for cloud providers)
   - Model selection
   - Temperature and token limits
   - Test connection before saving

4. **Test your setup:**
   - Use the "Test Connection" button to verify LLM connectivity
   - Try commands like "tell me about artificial intelligence" to test real LLM responses

**Getting API Keys:**

- **OpenAI**: https://platform.openai.com/api-keys
- **Anthropic**: https://console.anthropic.com/
- **Ollama**: Install from https://ollama.ai/ (local only)

### Testing Real LLM Integration

### âœ… **Infrastructure Now Ready**

The app now includes **real LLM integration** instead of mock responses! Agents will use actual AI models for intelligent responses.

### Quick LLM Test

1. **Open the app** at `http://localhost:8090`
2. **Navigate to LLM Settings** tab
3. **Choose a provider:**
   - **Mock**: No setup required (simulated responses)
   - **OpenAI**: Requires API key from https://platform.openai.com/api-keys
   - **Anthropic**: Requires API key from https://console.anthropic.com/
   - **Ollama**: Requires local Ollama installation

4. **Test the connection:**
   - Click "Test Connection" to verify API connectivity
   - Try commands like "tell me about artificial intelligence"
   - Agents now provide real AI-generated responses!

### Example Commands to Test

```
help
status
run workflow
tell me about machine learning
search for information about climate change
```

## What's New in v0.7.0-alpha

### ðŸš€ Enhanced MCP Workflow Processing

- **Improved Reliability**: Better error handling and recovery mechanisms
- **Performance Optimization**: Faster workflow execution with optimized data processing
- **Enhanced Monitoring**: More detailed progress tracking and metrics

### ðŸ”’ Security & Configuration

- **Secure Configuration Management**: Environment variables for sensitive data
- **Git Safety**: Automatic exclusion of secrets from version control
- **MCP Integration**: Improved Model Context Protocol support

### ðŸ§ª Expanded Testing Suite

- **Additional Test Cases**: More comprehensive system validation
- **Performance Monitoring**: Real-time metrics and diagnostics
- **Error Reporting**: Enhanced debugging and troubleshooting tools

### ðŸŽ¯ User Experience Improvements

- **Better Error Messages**: Clear, actionable error reporting
- **Voice Recognition**: Improved reliability and accuracy
- **Interface Polish**: Enhanced UI/UX across all components

### ðŸ“š Documentation

- **User Guide**: Comprehensive instructions and troubleshooting
- **Configuration Guide**: Step-by-step setup instructions
- **FAQ Section**: Common questions and solutions

### ðŸ”§ Technical Enhancements

- **Code Quality**: Improved TypeScript types and error handling
- **Build Process**: Optimized packaging and deployment
- **Dependency Updates**: Latest stable versions of all packages

---

## Basic Commands

### `help`

- **Description**: Displays a list of available commands
- **Usage**: Simply type `help` or say "help"
- **Example**:
  ```
  > help
  Available commands: run workflow, query [db] [params], status, clear, feedback [on|off], voice [on|off]
  ```

### `status`

- **Description**: Provides an overview of the system's current state
- **Usage**: Type `status` or say "status"
- **Example**:
  ```
  > status
  System status: OPERATIONAL
  McP processors: ACTIVE (3/3)
  Memory usage: 1.2GB / 4GB
  Storage status: CONNECTED
  Feedback loop: ENABLED
  Voice interface: ENABLED
  ```

### `clear`

- **Description**: Clears the console log
- **Usage**: Type `clear` or say "clear"
- **Example**:
  ```
  > clear
  Console cleared.
  ```

## Workflow Commands

### `run workflow`

- **Description**: Initiates the real McP (Monitor-Contextualize-Personalize) workflow with actual data processing
- **Usage**: Type `run workflow` or click "Run MCP Workflow" button in dashboard
- **Real Phases**:
  1. Monitor: Captures and validates real user interaction data
  2. Contextualize: Performs live semantic search and user pattern analysis
  3. Personalize: Generates LLM-powered adaptive responses with personalization
  4. Feedback: Updates agent knowledge based on real response effectiveness
- **Example**:
  ```bash
  > run workflow
  MCP Workflow initiated with real data processing...
  Monitor phase: Captured trigger with 95% confidence
  Contextualize phase: Enriched context with 3 relevant items
  Personalize phase: Generated response with 91% confidence
  Workflow completed in 1.2 seconds
  ```

### `feedback [on|off]`

- **Description**: Controls the agent's self-learning feedback loop
- **Usage**: Type `feedback on` or `feedback off`
- **Example**:

  ```
  > feedback on
  Feedback loop enabled. Agent will continuously learn from interactions.

  > feedback off
  Feedback loop disabled. Agent will not adapt from interactions.

  > feedback
  Current feedback status: ENABLED
  ```

## Voice Interface

### `voice [on|off]`

- **Description**: Controls the agent's voice response capability
- **Usage**: Type `voice on` or `voice off`
- **Example**:

  ```
  > voice on
  Voice output enabled.

  > voice off
  Voice output disabled.

  > voice
  Current voice status: ENABLED
  ```

### Using Voice Commands

- Click the microphone button to start voice recognition
- Speak your command clearly
- The agent will process your speech and execute the command
- If voice output is enabled, the agent will also respond using speech synthesis

## Knowledge Queries

### `tell me about [topic]`

- **Description**: Queries the agent's knowledge base about a specific topic
- **Usage**: Type `tell me about [topic]` or ask using voice
- **Example**:
  ```
  > tell me about feedback loops
  Retrieving information about "feedback loops"...
  feedback loops are part of the agent's knowledge base. They relate to adaptive learning systems that continuously evolve through feedback and context-aware interactions.
  ```

## Database Interaction

### `query`

- **Description**: Executes database queries
- **Usage**: `query [db] [parameters]`
- **Example**:
  ```
  > query interactions limit 5
  Query returned 5 results.
  ```

## Conversational Interaction

The agent can also respond to natural language questions and commands that don't match specific command formats. Simply type your question or use voice input to engage in a conversation.

## Troubleshooting

- If a command is not recognized, the console will return an error message
- Commands are case-insensitive
- Refer to the `help` command for the most up-to-date list of available commands
- If voice recognition fails, try speaking more clearly or switch to text input
- If voice output is not working, check your browser's audio settings

## Versions

Current Console Version: v0.7.0-alpha

## Quick Tips

- Press Enter to execute a typed command
- Click the microphone button to use voice commands
- Toggle voice output on/off using the speaker button
- Use the command history for quick access to previous commands
- The console provides real-time feedback for each command execution
- The feedback loop enables continuous agent improvement and adaptation
